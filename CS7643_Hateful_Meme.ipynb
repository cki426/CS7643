{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS7643 Hateful-Meme.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+a1eOhWetuwRs1aUbgQEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cki426/CS7643/blob/main/CS7643_Hateful_Meme.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKEJBLeD1jR6",
        "outputId": "c5d7d5de-67ab-4f22-8d67-fd7fc92fedad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/deeplearning'\n",
            "/content/gdrive/MyDrive/deeplearning\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd 'gdrive/MyDrive/deeplearning'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmf\n",
        "!pip install --editable ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pMpc3PHU1uqP",
        "outputId": "e8df7724-4633-4236-b5e8-eccee979e72a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/deeplearning/mmf\n",
            "Obtaining file:///content/gdrive/My%20Drive/deeplearning/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning (to revision 9b011606f) to /tmp/pip-install-ihgcbdak/pytorch-lightning_d2c2bd55fe5a40bbaa31d53df30b9517\n",
            "  Running command git clone -q https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-install-ihgcbdak/pytorch-lightning_d2c2bd55fe5a40bbaa31d53df30b9517\n",
            "\u001b[33m  WARNING: Did not find branch or tag '9b011606f', assuming revision or ref.\u001b[0m\n",
            "  Running command git checkout -q 9b011606f\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  From https://github.com/PyTorchLightning/lightning-tutorials\n",
            "   * branch            290fb466de1fcc2ac6025f74b56906592911e856 -> FETCH_HEAD\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch<=1.9.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.9.0)\n",
            "Requirement already satisfied: ftfy==5.8 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (5.8)\n",
            "Requirement already satisfied: transformers<=4.10.1,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (4.10.1)\n",
            "Requirement already satisfied: fasttext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.9.1)\n",
            "Requirement already satisfied: numpy<=1.21.4,>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.21.4)\n",
            "Requirement already satisfied: torchaudio<=0.9.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.9.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (5.4.8)\n",
            "Requirement already satisfied: pillow==9.0.1 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (9.0.1)\n",
            "Requirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.0)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.23.0)\n",
            "Requirement already satisfied: matplotlib==3.3.4 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.3.4)\n",
            "Requirement already satisfied: torchtext==0.5.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.0)\n",
            "Requirement already satisfied: nltk==3.4.5 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.4.5)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.43.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (4.49.0)\n",
            "Requirement already satisfied: lmdb==0.98 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.98)\n",
            "Requirement already satisfied: GitPython==3.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (3.1.0)\n",
            "Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.0.2)\n",
            "Requirement already satisfied: iopath==0.1.8 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.1.8)\n",
            "Requirement already satisfied: datasets==1.2.1 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.2.1)\n",
            "Requirement already satisfied: omegaconf<=2.1,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.1.0)\n",
            "Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.3)\n",
            "Requirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: torchvision<=0.10.0,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.10.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (2.8.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (21.3)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (2022.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (4.2.0)\n",
            "Requirement already satisfied: pyDeprecate<0.4.0,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.8.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.3.4)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (6.0.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (4.11.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (2.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==5.8->mmf==1.0.0rc12) (0.2.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython==3.1.0->mmf==1.0.0rc12) (4.0.9)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath==0.1.8->mmf==1.0.0rc12) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (0.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->mmf==1.0.0rc12) (1.15.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf==1.0.0rc12) (0.29.28)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (1.24.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf==1.0.0rc12) (1.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->mmf==1.0.0rc12) (0.1.96)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (3.8.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython==3.1.0->mmf==1.0.0rc12) (5.0.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf<=2.1,>=2.0.6->mmf==1.0.0rc12) (4.8)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.44.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets==1.2.1->mmf==1.0.0rc12) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (3.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (3.6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (0.10.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.7.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (21.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning@ git+https://github.com/PyTorchLightning/pytorch-lightning@9b011606f->mmf==1.0.0rc12) (2.0.12)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->mmf==1.0.0rc12) (2022.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.1,>=3.4.0->mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (3.1.0)\n",
            "Installing collected packages: mmf\n",
            "  Running setup.py develop for mmf\n",
            "Successfully installed mmf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PYTHONPATH\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/gdrive/MyDrive/deeplearning/mmf\"\n",
        "!echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJTY2_4x1zej",
        "outputId": "41709750-2090-46e8-fb66-99845d6f23a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n",
            "/env/python:/content/gdrive/MyDrive/deeplearning/mmf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/deeplearning\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrPibJ-h13vK",
        "outputId": "c245b50c-8fd7-4401-fbfb-7804108a711b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/deeplearning\n",
            "/content/gdrive/MyDrive/deeplearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_convert_hm --zip_file hateful_memes.zip --password '' --bypass_checksum=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fybg02QH152w",
        "outputId": "d1e76615-8bad-4e0b-b8a4-39a81a4f2dcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/deeplearning/mmf/mmf/utils/configuration.py:582: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n",
            "  \"Device specified is 'cuda' but cuda is not present. \"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
            "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "Data folder is /root/.cache/torch/mmf/data\n",
            "Zip path is hateful_memes.zip\n",
            "Copying hateful_memes.zip\n",
            "Unzipping hateful_memes.zip\n",
            "Extracting the zip can take time. Sit back and relax.\n",
            "Moving train.jsonl\n",
            "Moving dev_seen.jsonl\n",
            "Moving test_seen.jsonl\n",
            "Moving dev_unseen.jsonl\n",
            "Moving test_unseen.jsonl\n",
            "Moving img\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd mmf\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra4CTDrs18mA",
        "outputId": "36c82f45-c731-453b-cff3-e21256785093"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/deeplearning/mmf\n",
            "/content/gdrive/MyDrive/deeplearning/mmf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_dir = \"./CC_full\"\n",
        "ckpt_file = ckpt_dir + \"/best.ckpt\""
      ],
      "metadata": {
        "id": "Bbkd2btqG49o"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine Tune"
      ],
      "metadata": {
        "id": "jV_3WApn2Rih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!mmf_run config=projects/visual_bert/configs/hateful_memes/defaults.yaml model=visual_bert dataset=hateful_memes run_type=train_val \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\ ### change resume_zoo based on diff pretrained model\n",
        "checkpoint.resume_pretrained=True \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=500 \\\n",
        "training.evaluation_interval=300 \\\n",
        "training.max_updates=2000 \\\n",
        "training.log_interval=200 \\\n",
        "training.lr_ratio=0.5 \\\n",
        "training.batch_size=4 \\\n",
        "training.num_workers=0 \\\n",
        "optimizer.params.lr=5.0e-05 \\\n",
        "env.save_dir=$ckpt_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y-WKnuu3HJQw",
        "outputId": "64a4941c-3e67-49e5-b8a8-faaade498a8c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
            "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option run_type to train_val\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.pretrained.cc.full\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to True\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.max_to_keep to 1\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.tensorboard to True\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.checkpoint_interval to 500\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 300\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 2000\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 200\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.lr_ratio to 0.5\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 4\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option training.num_workers to 0\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option optimizer.params.lr to 5.0e-05\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.utils.configuration: \u001b[0mOverriding option env.save_dir to ./CC_adaboost\n",
            "/content/gdrive/MyDrive/deeplearning/mmf/mmf/utils/configuration.py:582: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n",
            "  \"Device specified is 'cuda' but cuda is not present. \"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf: \u001b[0mLogging to: ./CC_adaboost/train.log\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=train_val', 'checkpoint.resume_zoo=visual_bert.pretrained.cc.full', 'checkpoint.resume_pretrained=True', 'checkpoint.max_to_keep=1', 'training.tensorboard=True', 'training.checkpoint_interval=500', 'training.evaluation_interval=300', 'training.max_updates=2000', 'training.log_interval=200', 'training.lr_ratio=0.5', 'training.batch_size=4', 'training.num_workers=0', 'optimizer.params.lr=5.0e-05', 'env.save_dir=./CC_adaboost'])\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf_cli.run: \u001b[0mUsing seed 22457811\n",
            "\u001b[32m2022-05-01T23:04:22 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:29 | mmf.utils.build: \u001b[0mpersistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False\n",
            "\u001b[32m2022-05-01T23:04:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:29 | mmf.utils.build: \u001b[0mpersistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False\n",
            "\u001b[32m2022-05-01T23:04:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:29 | mmf.utils.build: \u001b[0mpersistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False\n",
            "\u001b[32m2022-05-01T23:04:29 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-05-01T23:04:29 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bert_model_name\": \"bert-base-uncased\",\n",
            "  \"bypass_transformer\": false,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_strategy\": \"plain\",\n",
            "  \"finetune_lr_multiplier\": 1,\n",
            "  \"freeze_base\": false,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"losses\": [\n",
            "    \"cross_entropy\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model\": \"visual_bert\",\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_strategy\": \"default\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"random_initialize\": false,\n",
            "  \"special_visual_initialize\": true,\n",
            "  \"training_head_type\": \"classification\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"visual_embedding_dim\": 2048,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"zerobias\": false\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.projection.bias', 'bert.embeddings.projection.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2022-05-01T23:04:35 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-05-01T23:04:35 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-05-01T23:04:35 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:37 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:37 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:37 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T23:04:37 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2022-05-01T23:04:37 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2022-05-01T23:43:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/2000, train/hateful_memes/cross_entropy: 0.6494, train/hateful_memes/cross_entropy/avg: 0.6494, train/total_loss: 0.6494, train/total_loss/avg: 0.6494, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 2000, lr: 0.00001, ups: 0.09, time: 38m 46s 366ms, time_since_start: 38m 48s 156ms, eta: 08h 25m 59s 087ms\n",
            "\u001b[32m2022-05-02T00:03:39 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-05-02T00:03:39 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-02T00:03:39 | mmf.utils.build: \u001b[0mpersistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False\n",
            "\u001b[32m2022-05-02T00:11:29 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 135\n",
            "\u001b[32m2022-05-02T00:11:29 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-05-02T00:11:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[32m2022-05-02T00:11:40 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-05-02T00:11:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-05-02T00:11:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-05-02T00:11:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/2000, val/hateful_memes/cross_entropy: 0.6966, val/total_loss: 0.6966, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5768, num_updates: 300, epoch: 1, iterations: 300, max_updates: 2000, val_time: 08m 15s 602ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.576765\n",
            "\u001b[32m2022-05-02T00:31:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/2000, train/hateful_memes/cross_entropy: 0.6161, train/hateful_memes/cross_entropy/avg: 0.6327, train/total_loss: 0.6161, train/total_loss/avg: 0.6327, experiment: run, epoch: 1, num_updates: 400, iterations: 400, max_updates: 2000, lr: 0.00001, ups: 0.17, time: 19m 54s 080ms, time_since_start: 01h 27m 13s 341ms, eta: 03h 50m 51s 339ms\n",
            "\u001b[32m2022-05-02T00:52:13 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2022-05-02T00:52:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[32m2022-05-02T00:52:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-05-02T00:52:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-05-02T01:12:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/2000, train/hateful_memes/cross_entropy: 0.6494, train/hateful_memes/cross_entropy/avg: 0.6967, train/total_loss: 0.6494, train/total_loss/avg: 0.6967, experiment: run, epoch: 1, num_updates: 600, iterations: 600, max_updates: 2000, lr: 0.00002, ups: 0.08, time: 41m 07s 991ms, time_since_start: 02h 08m 21s 332ms, eta: 06h 57m 30s 109ms\n",
            "\u001b[32m2022-05-02T01:12:57 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2022-05-02T01:12:57 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-02T01:12:57 | mmf.utils.build: \u001b[0mpersistent_workers cannot be used together with num_workers == 0; setting persistent_workers to False\n",
            "\u001b[32m2022-05-02T01:20:52 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 135\n",
            "\u001b[32m2022-05-02T01:20:52 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-05-02T01:20:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[32m2022-05-02T01:21:03 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2022-05-02T01:21:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2022-05-02T01:21:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2022-05-02T01:21:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/2000, val/hateful_memes/cross_entropy: 0.6762, val/total_loss: 0.6762, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.0657, val/hateful_memes/roc_auc: 0.6052, num_updates: 600, epoch: 1, iterations: 600, max_updates: 2000, val_time: 08m 21s 272ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.605206\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/bin/mmf_run\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('mmf', 'console_scripts', 'mmf_run')())\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf_cli/run.py\", line 133, in run\n",
            "    main(configuration, predict=predict)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf_cli/run.py\", line 56, in main\n",
            "    trainer.train()\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/trainers/mmf_trainer.py\", line 145, in train\n",
            "    self.training_loop()\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/trainers/core/training_loop.py\", line 33, in training_loop\n",
            "    self.run_training_epoch()\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/trainers/core/training_loop.py\", line 91, in run_training_epoch\n",
            "    report = self.run_training_batch(batch, num_batches_for_this_update)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/trainers/core/training_loop.py\", line 166, in run_training_batch\n",
            "    report = self._forward(batch)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/trainers/core/training_loop.py\", line 200, in _forward\n",
            "    model_output = self.model(prepared_batch)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/models/base_model.py\", line 309, in __call__\n",
            "    model_output = super().__call__(sample_list, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/models/visual_bert.py\", line 599, in forward\n",
            "    getattr_torchscriptable(sample_list, \"masked_lm_labels\", None),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/models/visual_bert.py\", line 378, in forward\n",
            "    image_text_alignment,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/models/visual_bert.py\", line 134, in forward\n",
            "    encoded_layers = self.encoder(embedding_output, extended_attention_mask)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/modules/hf_layers.py\", line 339, in forward\n",
            "    encoder_attention_mask,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/modules/hf_layers.py\", line 283, in forward\n",
            "    hidden_states, attention_mask, head_mask\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/modules/hf_layers.py\", line 247, in forward\n",
            "    encoder_attention_mask,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/gdrive/MyDrive/deeplearning/mmf/mmf/modules/hf_layers.py\", line 170, in forward\n",
            "    mixed_query_layer = self.query(hidden_states)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\", line 96, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1847, in linear\n",
            "    return torch._C._nn.linear(input, weight, bias)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mmf_run config=projects/visual_bert/configs/hateful_memes/defaults.yaml model=visual_bert dataset=hateful_memes \\\n",
        "run_type=test checkpoint.resume_pretrained=False checkpoint.resume_file=$ckpt_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h7Hk7XokHWn-",
        "outputId": "4aff457d-393a-4b7e-e13e-5176c3d27083"
      },
      "execution_count": 24,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_USER_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/resolvers/__init__.py:13: UserWarning: The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\n",
            "  \"The `env` resolver is deprecated, see https://github.com/omry/omegaconf/issues/573\"\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/visual_bert/configs/hateful_memes/defaults.yaml\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to ./CC_adaboost/best.ckpt\n",
            "/content/gdrive/MyDrive/deeplearning/mmf/mmf/utils/configuration.py:582: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n",
            "  \"Device specified is 'cuda' but cuda is not present. \"\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_LOG_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_REPORT_DIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_TENSORBOARD_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/omegaconf/grammar_visitor.py:257: UserWarning: In the sequence `MMF_WANDB_LOGDIR,` some elements are missing: please replace them with empty quoted strings. See https://github.com/omry/omegaconf/issues/572 for details.\n",
            "  category=UserWarning,\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf: \u001b[0mLogging to: ./save/train.log\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/visual_bert/configs/hateful_memes/defaults.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_pretrained=False', 'checkpoint.resume_file=./CC_adaboost/best.ckpt'])\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf_cli.run: \u001b[0mTorch version: 1.9.0+cu102\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf_cli.run: \u001b[0mUsing seed 55693455\n",
            "\u001b[32m2022-05-01T22:09:55 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
            "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T22:10:03 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T22:10:03 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[32m2022-05-01T22:10:03 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-05-01T22:10:03 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-05-01T22:10:03 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2022-05-01T22:10:03 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Model config BertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bert_model_name\": \"bert-base-uncased\",\n",
            "  \"bypass_transformer\": false,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_strategy\": \"plain\",\n",
            "  \"finetune_lr_multiplier\": 1,\n",
            "  \"freeze_base\": false,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"losses\": [\n",
            "    \"cross_entropy\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model\": \"visual_bert\",\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_strategy\": \"default\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"random_initialize\": false,\n",
            "  \"special_visual_initialize\": true,\n",
            "  \"training_head_type\": \"classification\",\n",
            "  \"transformers_version\": \"4.10.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"visual_embedding_dim\": 2048,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"zerobias\": false\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/torch/mmf/distributed_-1/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing VisualBERTBase: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing VisualBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing VisualBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2022-05-01T22:10:09 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2022-05-01T22:10:09 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[32m2022-05-01T22:10:09 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T22:10:14 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2022-05-01T22:10:14 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 900\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 900\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 1\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.trainers.mmf_trainer: \u001b[0mStarting inference on test set\n",
            "\u001b[32m2022-05-01T22:10:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 32/32 [25:23<00:00, 47.61s/it]\n",
            "\u001b[32m2022-05-01T22:35:40 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished training. Loaded 32\n",
            "\u001b[32m2022-05-01T22:35:40 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n",
            "\u001b[32m2022-05-01T22:35:40 | mmf.trainers.callbacks.logistics: \u001b[0mtest/hateful_memes/cross_entropy: 0.7126, test/total_loss: 0.7126, test/hateful_memes/accuracy: 0.6355, test/hateful_memes/binary_f1: 0.0853, test/hateful_memes/roc_auc: 0.6359\n",
            "\u001b[32m2022-05-01T22:35:40 | mmf.trainers.callbacks.logistics: \u001b[0mFinished run in 25m 31s 694ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensembling method"
      ],
      "metadata": {
        "id": "wKpSLLnEihjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    f1_score,\n",
        "    precision_recall_curve,\n",
        "    precision_recall_fscore_support,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "data = pd.read_csv(\"input.csv\")\n",
        "r = []\n",
        "for i in range(1,12):\n",
        "    x1 = data.iloc[:,0]\n",
        "    x2 = data.iloc[:,i]\n",
        "    r.append(roc_auc_score(x1, x2))"
      ],
      "metadata": {
        "id": "WVwTQlgHigpW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}